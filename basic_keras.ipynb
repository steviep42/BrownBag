{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfK/VsnU49DPCMt0TjFjjx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steviep42/BrownBag/blob/master/basic_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shP_wBWN6lyp",
        "colab_type": "text"
      },
      "source": [
        "Import some libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1qDPpOW6pJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxt4v6F16t-j",
        "colab_type": "text"
      },
      "source": [
        "DATA LOADING - Get the Pima Indians Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjvlU9GN6x8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pmurl = \"https://raw.githubusercontent.com/steviep42/bios534_spring_2020/master/data/pima_10.csv\"\n",
        "pm = pd.read_csv(pmurl, sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmPsnkp1660A",
        "colab_type": "text"
      },
      "source": [
        "Specify the Predictor Variables \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it3_YEDU6_yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pm.iloc[:,0:8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWBE6Jyr7eoL",
        "colab_type": "text"
      },
      "source": [
        "So now we create a train / test pair with proportions of"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQNe5hfk7f5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.ravel(pm.diabetes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tUFCn3t7nGe",
        "colab_type": "text"
      },
      "source": [
        "So now we create a train / test pair with proportions of 70 / 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS_OZCXo7xJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7rI2vf475nK",
        "colab_type": "text"
      },
      "source": [
        "SCALING -  Let's do some scaling on the data. There are different ways to scale the data. We'll use the standard scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1buD-SmE77t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5umWGdaG8Gss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler().fit(X_train)\n",
        "\n",
        "# Scale the train set\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "# Scale the test set\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8Ta7-aU8jjG",
        "colab_type": "text"
      },
      "source": [
        "DEFINE THE KERAS MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5ggZNo-8miW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e95e09b7-e1d1-4d09-b566-c5b1fe91415e"
      },
      "source": [
        "# Import `Sequential` from `keras.models`\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Import `Dense` from `keras.layers`\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialize the constructor\n",
        "model = Sequential()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nWX2Gdo85gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "8d55352c-48e6-422e-dea1-c18c9077db6a"
      },
      "source": [
        "shape_val = X_train.shape[1]\n",
        "# Add an input layer\n",
        "model.add(Dense(63, activation='relu', input_shape=(shape_val,)))\n",
        "\n",
        "# Add one hidden layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Add one hidden layer\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "# Add an output layer\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DueCEx-69BvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64f1a2a0-7b92-4432-c958-1ca157db5407"
      },
      "source": [
        "# Model output shape\n",
        "model.output_shape\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Model config\n",
        "model.get_config()\n",
        "\n",
        "# List all weight tensors\n",
        "model.get_weights()\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 63)                567       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2048      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 3,160\n",
            "Trainable params: 3,160\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-4.59945053e-02,  1.31292284e-01, -1.98729247e-01,\n",
              "          2.48934776e-01,  2.26707071e-01, -1.98303342e-01,\n",
              "          1.89377517e-01,  1.88746125e-01, -2.20725134e-01,\n",
              "         -2.19502673e-01,  2.01156914e-01, -4.30580527e-02,\n",
              "         -1.26631498e-01, -2.03239709e-01,  3.37423682e-02,\n",
              "          1.33364469e-01,  2.24564761e-01,  6.76423907e-02,\n",
              "         -2.73760617e-01,  2.53420174e-02, -3.58573198e-02,\n",
              "         -1.46580279e-01, -1.31645203e-01,  7.93586671e-02,\n",
              "          8.39715600e-02, -3.17143202e-02, -2.81807065e-01,\n",
              "          3.70964706e-02,  8.63336623e-02, -1.24607399e-01,\n",
              "          6.48621619e-02,  2.02278614e-01,  5.44289947e-02,\n",
              "         -7.17225224e-02, -2.87995011e-01, -1.66751444e-02,\n",
              "         -6.68606013e-02, -2.79228032e-01,  2.79959649e-01,\n",
              "          1.44041240e-01, -1.00159183e-01,  2.29318112e-01,\n",
              "          2.64752805e-02,  2.77315646e-01,  2.78059751e-01,\n",
              "          2.69979805e-01,  5.45305014e-03, -1.08075440e-02,\n",
              "         -2.09032923e-01,  8.34290683e-02,  2.39174753e-01,\n",
              "          2.22822160e-01, -2.06630230e-02, -1.60489246e-01,\n",
              "         -2.04752445e-01, -1.65716559e-01, -6.76360875e-02,\n",
              "         -2.13544905e-01,  9.23442245e-02,  1.74026787e-02,\n",
              "          2.16284543e-01, -1.33267984e-01, -9.37100202e-02],\n",
              "        [-2.51485139e-01,  3.87344360e-02, -2.52106220e-01,\n",
              "          2.68978775e-02, -1.50138989e-01, -2.44377762e-01,\n",
              "         -3.59775722e-02,  1.53926164e-01, -2.88228989e-02,\n",
              "          1.75104201e-01, -8.94591212e-02, -5.93270361e-02,\n",
              "          1.17909163e-01, -1.42449766e-01,  2.66986221e-01,\n",
              "         -2.68802166e-01, -2.37759233e-01,  9.25841630e-02,\n",
              "          1.74674541e-01,  4.12958860e-02, -1.63302273e-01,\n",
              "         -2.88717330e-01, -1.87843516e-01, -1.96997792e-01,\n",
              "         -9.88233238e-02,  2.51873642e-01, -6.39122874e-02,\n",
              "          2.65085489e-01, -1.16638735e-01, -1.06164902e-01,\n",
              "         -5.18004149e-02,  1.88983351e-01, -2.46888891e-01,\n",
              "         -3.32249105e-02, -8.29414874e-02, -9.62671638e-02,\n",
              "         -1.04187533e-01,  6.30570054e-02,  8.19776952e-02,\n",
              "          5.64572513e-02, -2.18594879e-01,  1.48725241e-01,\n",
              "         -4.66860086e-02, -7.13467300e-02,  1.73221767e-01,\n",
              "         -2.28792220e-01,  2.41137832e-01, -7.98982382e-03,\n",
              "          1.16718769e-01,  7.11264610e-02,  1.39219224e-01,\n",
              "         -3.46064270e-02, -1.31791025e-01, -4.04383242e-02,\n",
              "          1.37566924e-01,  2.06260651e-01, -2.39164382e-01,\n",
              "          2.63664722e-02,  6.08329177e-02, -1.66077182e-01,\n",
              "         -1.39075488e-01, -1.99697077e-01, -1.73761547e-01],\n",
              "        [-8.75820369e-02, -9.06801969e-02,  1.23318404e-01,\n",
              "          1.24656260e-02,  1.91707611e-01, -2.51377225e-02,\n",
              "         -5.73310256e-02,  5.75189888e-02, -5.00004739e-02,\n",
              "         -1.69834495e-03,  6.56126440e-02, -8.47747922e-03,\n",
              "          7.38410056e-02, -2.00601488e-01, -4.54361588e-02,\n",
              "          1.50208026e-01,  2.88618833e-01, -2.40617692e-02,\n",
              "         -2.42089137e-01, -2.20440343e-01,  3.16142440e-02,\n",
              "          2.30757445e-01, -1.45244017e-01, -2.84651339e-01,\n",
              "          1.37183517e-01,  5.82128763e-04,  1.40485436e-01,\n",
              "         -5.13257235e-02,  2.66890138e-01, -2.02339739e-01,\n",
              "         -2.31478512e-02, -1.79685205e-01,  3.79750431e-02,\n",
              "          8.73309374e-02,  2.05207229e-01, -1.09616950e-01,\n",
              "         -1.07928932e-01,  2.36437589e-01,  1.69288665e-01,\n",
              "          2.61686534e-01, -1.34521842e-01,  1.83790326e-02,\n",
              "          2.62238771e-01, -4.85846400e-03,  2.67032832e-01,\n",
              "          1.03403777e-01, -1.34491980e-01, -2.58250505e-01,\n",
              "          2.01691419e-01, -7.18652308e-02, -1.12616405e-01,\n",
              "         -7.22208619e-03,  2.30586261e-01, -2.29546100e-01,\n",
              "          2.78630704e-01, -2.14483082e-01, -1.86905354e-01,\n",
              "          1.66071355e-01, -1.93809032e-01,  1.53982997e-01,\n",
              "          8.68976116e-03,  6.35856390e-03, -1.93152547e-01],\n",
              "        [-8.87394249e-02, -1.65236682e-01,  2.89926201e-01,\n",
              "          1.26300067e-01,  8.49035382e-03,  5.31924069e-02,\n",
              "         -2.35069498e-01,  2.14723200e-01, -3.58520448e-02,\n",
              "          1.44345760e-01,  2.65871257e-01, -6.05528355e-02,\n",
              "         -2.23655105e-02,  6.61625862e-02, -2.25517392e-01,\n",
              "          1.00692809e-02, -1.49178177e-01,  1.40231252e-02,\n",
              "          3.88659835e-02,  2.02664644e-01, -4.77167517e-02,\n",
              "         -9.86036807e-02, -1.52060986e-01, -2.66997159e-01,\n",
              "          1.45626307e-01,  6.89538419e-02,  2.40295976e-01,\n",
              "         -5.26224077e-02,  2.16251880e-01, -1.68436378e-01,\n",
              "         -3.51369977e-02, -7.84844607e-02, -1.53326765e-01,\n",
              "         -2.32757300e-01, -7.87668973e-02,  2.29967326e-01,\n",
              "         -2.61225432e-01,  1.86966419e-01,  2.35280186e-01,\n",
              "          1.29208535e-01, -2.09094405e-01, -1.14417180e-01,\n",
              "          2.14952439e-01, -2.31802925e-01,  3.38369012e-02,\n",
              "          1.85029656e-01,  1.80335522e-01, -1.10798940e-01,\n",
              "          1.26183897e-01, -9.64996219e-02, -1.04518816e-01,\n",
              "          7.32599795e-02,  9.93008614e-02,  1.76602572e-01,\n",
              "         -2.82153070e-01,  2.10339099e-01,  2.44119167e-02,\n",
              "          2.73138583e-02, -2.36000240e-01, -5.08904606e-02,\n",
              "          1.67224705e-02, -2.73127079e-01, -2.58229226e-01],\n",
              "        [-2.40409032e-01,  1.82141960e-02,  1.93840563e-01,\n",
              "         -2.16234848e-01, -9.97614861e-02,  9.44128633e-02,\n",
              "         -2.68780172e-01,  2.22742558e-03,  4.99674082e-02,\n",
              "         -8.67976099e-02, -2.48514935e-01, -8.62553418e-02,\n",
              "          1.48058414e-01, -5.28187007e-02,  2.31482714e-01,\n",
              "         -1.54869989e-01, -9.82711464e-02,  2.45837241e-01,\n",
              "         -2.25643605e-01,  2.08789110e-02,  2.65354723e-01,\n",
              "         -1.59898669e-01,  1.38312131e-01, -2.06892684e-01,\n",
              "         -1.22966737e-01, -2.04171494e-01,  6.67289793e-02,\n",
              "         -2.16727972e-01, -2.22803146e-01, -1.80049300e-01,\n",
              "         -2.24802762e-01, -1.99509531e-01, -9.74752009e-02,\n",
              "          2.68369913e-04,  1.33147031e-01, -8.92111361e-02,\n",
              "         -3.39648426e-02,  1.76112294e-01,  4.65413928e-03,\n",
              "         -1.18911698e-01,  1.39823943e-01,  1.60934418e-01,\n",
              "          2.17163771e-01, -5.24329990e-02,  1.64815754e-01,\n",
              "         -2.27257669e-01,  1.00064844e-01, -1.92230403e-01,\n",
              "          1.01650059e-02,  1.63906306e-01, -2.14440942e-01,\n",
              "          6.28010631e-02, -2.81442642e-01, -2.74233669e-01,\n",
              "          2.89419919e-01,  2.88656652e-02, -9.50970948e-02,\n",
              "         -1.08199239e-01,  2.59246737e-01, -5.77095151e-02,\n",
              "          1.47734463e-01,  1.68910623e-03, -1.63591638e-01],\n",
              "        [-1.84253693e-01,  1.08415902e-01,  2.29772002e-01,\n",
              "          1.52158707e-01,  3.88782620e-02,  1.26960278e-01,\n",
              "         -4.37078178e-02,  1.24125928e-01,  7.95156360e-02,\n",
              "          5.09825349e-03,  2.13241130e-01,  2.68207103e-01,\n",
              "         -2.18446404e-01,  1.47226036e-01,  1.21322602e-01,\n",
              "          9.71962512e-02, -2.13455990e-01, -1.92680836e-01,\n",
              "          1.76258743e-01, -8.28243643e-02,  8.94910693e-02,\n",
              "          1.38945460e-01, -2.38841683e-01, -8.91924202e-02,\n",
              "         -5.22350520e-02,  1.34349465e-01,  3.51989567e-02,\n",
              "         -2.08304852e-01, -6.93511963e-02,  4.61216867e-02,\n",
              "         -1.15585998e-01, -5.62651306e-02, -1.88823953e-01,\n",
              "         -1.22888967e-01,  1.06161088e-01, -2.55933940e-01,\n",
              "         -1.60486549e-01, -9.46228802e-02, -2.65600115e-01,\n",
              "          5.70585728e-02,  7.87527561e-02, -3.48278582e-02,\n",
              "          6.57425821e-02, -9.27886963e-02, -1.66195840e-01,\n",
              "          9.52726603e-02, -1.99932784e-01,  1.70895517e-01,\n",
              "         -1.28919095e-01, -1.00011140e-01,  2.48891443e-01,\n",
              "          2.82336146e-01, -1.48359835e-02, -1.24879166e-01,\n",
              "          2.41982311e-01,  2.39075512e-01,  2.60774493e-02,\n",
              "          1.92231447e-01,  1.32026941e-01, -1.85880661e-02,\n",
              "          3.38795781e-02, -2.86753058e-01, -1.28245547e-01],\n",
              "        [ 2.04105288e-01, -1.65730149e-01, -2.88417637e-01,\n",
              "         -4.44418639e-02, -2.74122059e-02,  2.07874775e-01,\n",
              "         -1.22424811e-01,  1.88794076e-01,  1.30680561e-01,\n",
              "         -1.46442562e-01,  1.96383446e-01, -1.17145181e-02,\n",
              "          2.41293639e-01,  4.77925837e-02, -1.09471053e-01,\n",
              "         -2.90540844e-01, -1.72331244e-01,  1.49477512e-01,\n",
              "          2.00898945e-02,  1.09476745e-01, -2.37879887e-01,\n",
              "          1.83126450e-01,  3.24715972e-02, -1.71536610e-01,\n",
              "          1.91994667e-01,  2.04373181e-01, -4.25125211e-02,\n",
              "          1.39956266e-01,  1.91924602e-01,  1.90241247e-01,\n",
              "          9.92879272e-03,  1.75529391e-01,  1.25492811e-02,\n",
              "         -1.52373314e-03,  9.11189914e-02,  1.26195550e-01,\n",
              "         -3.69282067e-02,  4.15699184e-02, -1.38616562e-03,\n",
              "          2.67587513e-01,  3.47439945e-02,  1.36911869e-01,\n",
              "          6.24298453e-02,  1.72078520e-01, -1.51898459e-01,\n",
              "          9.18029845e-02,  6.79939389e-02,  1.48548573e-01,\n",
              "          2.25546926e-01, -1.14853755e-01,  5.12171984e-02,\n",
              "         -2.47656897e-01, -1.73907369e-01, -2.86834717e-01,\n",
              "         -2.11642325e-01, -4.95461524e-02, -1.02025717e-01,\n",
              "          4.22772169e-02, -2.75642633e-01,  1.60531402e-01,\n",
              "          6.36794865e-02, -1.06953070e-01, -8.30164105e-02],\n",
              "        [-2.49991417e-01,  6.68318272e-02,  2.33810514e-01,\n",
              "         -1.70935079e-01,  2.53567666e-01, -1.52821928e-01,\n",
              "          2.81965226e-01, -1.10006467e-01,  2.84675032e-01,\n",
              "         -6.92553520e-02, -3.31968367e-02,  1.56894356e-01,\n",
              "          1.88442051e-01,  2.78853267e-01,  6.75255358e-02,\n",
              "         -1.17735460e-01,  1.25288486e-01,  2.72385865e-01,\n",
              "          1.46159500e-01,  1.74803108e-01,  2.33611315e-01,\n",
              "          2.76120871e-01, -3.06414366e-02,  2.08447188e-01,\n",
              "         -1.52162179e-01, -2.00071201e-01,  8.74344110e-02,\n",
              "          7.23237693e-02, -2.88372189e-01, -6.19519651e-02,\n",
              "          3.70734036e-02, -2.27180526e-01, -2.06279650e-01,\n",
              "         -2.53802836e-02,  1.11891776e-01, -8.74632597e-03,\n",
              "          1.49853945e-01, -3.87237668e-02,  2.69825608e-01,\n",
              "         -1.15364417e-01,  2.08236217e-01, -2.63460755e-01,\n",
              "          1.87140852e-01, -2.24539667e-01,  2.78985053e-01,\n",
              "          5.80592453e-02, -1.00225985e-01, -2.65597135e-01,\n",
              "          1.48881614e-01, -1.96154088e-01, -1.50770843e-02,\n",
              "          2.67412931e-01, -2.47086555e-01, -1.97260320e-01,\n",
              "          6.88143969e-02,  1.81372672e-01, -1.37342632e-01,\n",
              "         -1.97522372e-01, -2.12001339e-01, -1.79176763e-01,\n",
              "         -2.64317125e-01,  2.40841120e-01, -9.23840106e-02]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[-0.17968741, -0.18328647,  0.22803864, ...,  0.11238071,\n",
              "          0.19955534, -0.02206972],\n",
              "        [-0.08384421,  0.10698232,  0.04028219, ...,  0.199875  ,\n",
              "          0.19869626, -0.06689073],\n",
              "        [ 0.08313265, -0.23075631,  0.09168112, ...,  0.16805777,\n",
              "         -0.15408424,  0.0101752 ],\n",
              "        ...,\n",
              "        [ 0.12285736,  0.08654028, -0.01374868, ...,  0.13783333,\n",
              "          0.09338728,  0.20800456],\n",
              "        [ 0.24220681,  0.05695516,  0.07402152, ..., -0.10720158,\n",
              "          0.05627269,  0.11409551],\n",
              "        [ 0.14643294, -0.04759046,  0.04951152, ...,  0.11112678,\n",
              "          0.15442115, -0.13094606]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32),\n",
              " array([[-0.12069432, -0.26384467,  0.03258264,  0.32632068, -0.21338165,\n",
              "         -0.1444488 ,  0.18536368,  0.3319526 , -0.11673893, -0.2738064 ,\n",
              "         -0.06500486,  0.13794595,  0.21485266, -0.24135873, -0.14012596,\n",
              "         -0.3318265 ],\n",
              "        [-0.09082291, -0.16829169, -0.13858254,  0.12273785, -0.20467436,\n",
              "          0.07940197,  0.34693775,  0.08805099,  0.10969004, -0.30347788,\n",
              "         -0.07481942, -0.2193482 ,  0.0549444 , -0.1285735 , -0.04600757,\n",
              "          0.1576496 ],\n",
              "        [-0.34734255,  0.16084883,  0.25689957, -0.02756017,  0.18596515,\n",
              "          0.15732929, -0.18052447,  0.3194503 ,  0.03934696,  0.1906859 ,\n",
              "         -0.0046106 ,  0.29244718, -0.05938077, -0.16411114,  0.3361099 ,\n",
              "         -0.30537271],\n",
              "        [ 0.00257713,  0.06311953,  0.06672657, -0.18616086, -0.26581326,\n",
              "         -0.33672348, -0.08657181,  0.08746549,  0.01849672,  0.14764175,\n",
              "          0.23196682,  0.21703622, -0.14443657,  0.08955505, -0.28766733,\n",
              "         -0.24343969],\n",
              "        [-0.23407802,  0.34133133, -0.06906444, -0.11518143,  0.22732756,\n",
              "         -0.20046557, -0.16573034, -0.20116918,  0.07835865, -0.17048846,\n",
              "          0.3273411 ,  0.19898167,  0.33240065,  0.0585165 , -0.33788243,\n",
              "         -0.2398181 ],\n",
              "        [-0.0443781 ,  0.23185453,  0.09991702,  0.05766794, -0.08871296,\n",
              "         -0.3123546 ,  0.11965144, -0.0459716 , -0.2235591 , -0.17484291,\n",
              "         -0.29344615, -0.3503186 ,  0.20211902, -0.05601341, -0.24145937,\n",
              "          0.09383211],\n",
              "        [ 0.2917635 ,  0.24265805, -0.17956783, -0.11615713,  0.33006588,\n",
              "         -0.27673241,  0.3433703 , -0.18678926,  0.01435834,  0.14789656,\n",
              "         -0.19366738, -0.07707286, -0.03155088, -0.18956995,  0.1835855 ,\n",
              "         -0.29065958],\n",
              "        [ 0.0286575 ,  0.13881847,  0.14683929, -0.2961164 ,  0.13733011,\n",
              "         -0.07512009,  0.2454463 , -0.11154585, -0.04680103, -0.17548582,\n",
              "          0.11649221,  0.11961359,  0.01159653,  0.16229358,  0.00839406,\n",
              "         -0.02129605],\n",
              "        [ 0.32857487,  0.3403711 , -0.30683032, -0.1766414 , -0.04802069,\n",
              "         -0.01275313, -0.35242605,  0.31478855,  0.09912273,  0.16151163,\n",
              "          0.0496805 , -0.07810554, -0.3045828 ,  0.20090541,  0.02539036,\n",
              "          0.32891372],\n",
              "        [ 0.18069127, -0.10654968, -0.23405392, -0.04401252,  0.21646073,\n",
              "         -0.17850631,  0.12579942, -0.1727472 ,  0.10362402,  0.2927465 ,\n",
              "         -0.17343622, -0.30969286, -0.13720974,  0.00456771, -0.2007258 ,\n",
              "         -0.12922198],\n",
              "        [ 0.34400073,  0.08900833,  0.33541676, -0.07267296,  0.22001657,\n",
              "          0.20981917, -0.00439641,  0.3210874 , -0.00280058,  0.18591496,\n",
              "         -0.16113287,  0.18206224,  0.246883  , -0.01073664,  0.1087794 ,\n",
              "          0.13453948],\n",
              "        [ 0.17216548,  0.23222163, -0.14616425, -0.25175095,  0.32705328,\n",
              "          0.01242709,  0.13659692,  0.09266153, -0.22664881,  0.03867984,\n",
              "         -0.2998756 , -0.0818699 ,  0.31290147,  0.15606901, -0.09452939,\n",
              "          0.16447368],\n",
              "        [-0.2072154 , -0.10862482,  0.1821188 ,  0.27494594, -0.27019492,\n",
              "         -0.18034561, -0.32943156,  0.05581018,  0.06390339, -0.06030557,\n",
              "         -0.00190875, -0.31167805,  0.1794543 ,  0.25181815, -0.00159895,\n",
              "          0.08727491],\n",
              "        [ 0.33708778, -0.16692841,  0.10093528, -0.23485506,  0.29585758,\n",
              "          0.318086  ,  0.16223332,  0.02036881,  0.11183524, -0.34860095,\n",
              "          0.02265435,  0.21657452, -0.14530413,  0.20891628,  0.03399801,\n",
              "          0.05005917],\n",
              "        [-0.26391017,  0.24561414,  0.08417535,  0.29923502, -0.09105876,\n",
              "         -0.01182085, -0.16534798, -0.16440591, -0.28426623, -0.22713408,\n",
              "          0.20185068,  0.16195884, -0.2823313 ,  0.24880978,  0.02475452,\n",
              "          0.26214275],\n",
              "        [-0.31945843,  0.0746671 , -0.08180654, -0.03236574,  0.19489285,\n",
              "         -0.10443002,  0.09659687,  0.10763428,  0.18355247, -0.20055881,\n",
              "          0.25208434, -0.30845532,  0.29781452, -0.06877607, -0.14094733,\n",
              "          0.11160409],\n",
              "        [ 0.19958016,  0.00235939,  0.265321  , -0.20173943,  0.03024146,\n",
              "          0.34652618,  0.12041101,  0.07104206,  0.15375862,  0.01014754,\n",
              "          0.02219665,  0.27365485,  0.20880082,  0.07547843, -0.08575687,\n",
              "          0.26794943],\n",
              "        [ 0.2215859 ,  0.2738746 , -0.30753383, -0.09303394, -0.32633066,\n",
              "          0.29378453,  0.09680936,  0.33191016, -0.20183164,  0.05940279,\n",
              "          0.11629292, -0.09100592,  0.08401579, -0.30760768,  0.1262663 ,\n",
              "          0.08969119],\n",
              "        [-0.01795405,  0.2980176 ,  0.03255373,  0.17069307,  0.03001261,\n",
              "         -0.29730773,  0.2208918 ,  0.26730576,  0.18588415, -0.07690385,\n",
              "          0.22719017,  0.21541032, -0.3489518 , -0.19469509, -0.3233452 ,\n",
              "          0.05514383],\n",
              "        [-0.07094714,  0.18752423,  0.0911535 , -0.00559026, -0.23473147,\n",
              "          0.25987485, -0.16788371,  0.32164428,  0.321385  , -0.01163843,\n",
              "         -0.14612801, -0.01893735,  0.32677773, -0.0785619 , -0.28995463,\n",
              "         -0.0732083 ],\n",
              "        [ 0.25653246,  0.14594012, -0.06405318, -0.02989054, -0.00903672,\n",
              "          0.00398996, -0.27465314, -0.0292173 , -0.32927975,  0.2236503 ,\n",
              "          0.01095641, -0.28208607,  0.03725401, -0.20076002, -0.16883327,\n",
              "          0.12926084],\n",
              "        [-0.33024508,  0.2926915 , -0.07440537,  0.23507902,  0.24749336,\n",
              "         -0.26930958, -0.16457333,  0.09561932, -0.09114239,  0.2508625 ,\n",
              "         -0.31112695, -0.23217341,  0.270036  ,  0.30230984, -0.02941564,\n",
              "         -0.34561628],\n",
              "        [ 0.02534744,  0.15402278, -0.04232201,  0.01784918,  0.03702861,\n",
              "         -0.28943235,  0.00564077,  0.13701013,  0.15853396, -0.21655843,\n",
              "          0.21749946,  0.09553888,  0.12943643,  0.20828936,  0.1412774 ,\n",
              "          0.1613054 ],\n",
              "        [ 0.14304161,  0.25975707,  0.04252246, -0.17732468,  0.2839755 ,\n",
              "          0.12610456, -0.03885502,  0.20163092,  0.01996621, -0.3269186 ,\n",
              "          0.03614151,  0.03360039,  0.00342965,  0.3449953 ,  0.31358603,\n",
              "          0.19344965],\n",
              "        [ 0.06333661,  0.18624625, -0.03848413, -0.06341541,  0.21257421,\n",
              "         -0.17385043, -0.17073081,  0.12060043, -0.27495408,  0.23903349,\n",
              "         -0.26953793,  0.35237363, -0.20739284,  0.1571565 , -0.19097412,\n",
              "         -0.13432461],\n",
              "        [ 0.29467055,  0.3448601 , -0.29657337,  0.19419369,  0.3296056 ,\n",
              "          0.02320006, -0.10180748, -0.01954022,  0.28969356,  0.2900248 ,\n",
              "          0.17593864, -0.11917873, -0.03084391, -0.16103324,  0.16251245,\n",
              "          0.03071073],\n",
              "        [ 0.18937632,  0.31903222, -0.24719429, -0.18027505, -0.19557141,\n",
              "          0.3175898 , -0.14059506, -0.11233635, -0.0740456 , -0.3082398 ,\n",
              "         -0.31822824,  0.32376722, -0.33102462, -0.08739316, -0.2306069 ,\n",
              "          0.3148599 ],\n",
              "        [ 0.18534407,  0.31447676,  0.3150998 , -0.3407142 ,  0.30875376,\n",
              "          0.16992715, -0.02001503,  0.28771165, -0.07397327,  0.26188746,\n",
              "         -0.20584184,  0.12222123,  0.32502374, -0.1699489 ,  0.10440102,\n",
              "         -0.17699906],\n",
              "        [ 0.24910936, -0.20903935, -0.15207915,  0.3022075 , -0.2861598 ,\n",
              "         -0.33727002, -0.20758958, -0.04566762, -0.05957213,  0.15362903,\n",
              "          0.20880613,  0.08724162, -0.07033905,  0.31122664, -0.02888584,\n",
              "          0.19231203],\n",
              "        [-0.299545  ,  0.17717883, -0.25927585,  0.20435718,  0.35185066,\n",
              "         -0.2521174 ,  0.19374332,  0.07232678, -0.09192649, -0.30182117,\n",
              "          0.27341226, -0.05932623, -0.12164178,  0.13694438,  0.10779756,\n",
              "         -0.18812077],\n",
              "        [-0.27824506, -0.21190761,  0.05052453, -0.05799136, -0.12988731,\n",
              "         -0.2907432 , -0.04775178, -0.30175424,  0.16923782, -0.3126615 ,\n",
              "         -0.2197439 , -0.28826666,  0.02573791,  0.06410274, -0.15197909,\n",
              "         -0.27330738],\n",
              "        [ 0.27756318, -0.25512955,  0.02333942,  0.04731432,  0.2959307 ,\n",
              "          0.04864731,  0.25657234,  0.32493857, -0.32139584,  0.0667322 ,\n",
              "         -0.06210944, -0.23549223,  0.00462428,  0.32620177,  0.25274876,\n",
              "         -0.17199673]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32),\n",
              " array([[ 0.5575936 ],\n",
              "        [ 0.54777825],\n",
              "        [-0.12400424],\n",
              "        [-0.45498502],\n",
              "        [ 0.20281428],\n",
              "        [-0.30197993],\n",
              "        [ 0.27357113],\n",
              "        [-0.20367348],\n",
              "        [ 0.24709052],\n",
              "        [ 0.07009131],\n",
              "        [ 0.23196954],\n",
              "        [-0.11328095],\n",
              "        [ 0.51511693],\n",
              "        [ 0.01700664],\n",
              "        [-0.21790123],\n",
              "        [ 0.06401455]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bl7xhH08zhr",
        "colab_type": "text"
      },
      "source": [
        "Now, compile the Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXqJ4TS79Mny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "99b07cb2-57f6-47ba-e2e7-4c16e86ec5bf"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjy6MGt69USF",
        "colab_type": "text"
      },
      "source": [
        "Fit The Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXhlmT2u9aVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6969c06e-e0ef-419f-f322-199740dde684"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50, batch_size=10,\n",
        "                    verbose=1)\n",
        "\n",
        "_,accuracy = model.evaluate(X_test, y_test,verbose=1)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "514/514 [==============================] - 1s 979us/step - loss: 0.7125 - acc: 0.4689\n",
            "Epoch 2/50\n",
            "514/514 [==============================] - 0s 136us/step - loss: 0.6473 - acc: 0.6673\n",
            "Epoch 3/50\n",
            "514/514 [==============================] - 0s 145us/step - loss: 0.6160 - acc: 0.6712\n",
            "Epoch 4/50\n",
            "514/514 [==============================] - 0s 147us/step - loss: 0.5940 - acc: 0.6770\n",
            "Epoch 5/50\n",
            "514/514 [==============================] - 0s 154us/step - loss: 0.5751 - acc: 0.6887\n",
            "Epoch 6/50\n",
            "514/514 [==============================] - 0s 145us/step - loss: 0.5574 - acc: 0.7082\n",
            "Epoch 7/50\n",
            "514/514 [==============================] - 0s 153us/step - loss: 0.5413 - acc: 0.7393\n",
            "Epoch 8/50\n",
            "514/514 [==============================] - 0s 151us/step - loss: 0.5257 - acc: 0.7588\n",
            "Epoch 9/50\n",
            "514/514 [==============================] - 0s 141us/step - loss: 0.5122 - acc: 0.7704\n",
            "Epoch 10/50\n",
            "514/514 [==============================] - 0s 150us/step - loss: 0.4992 - acc: 0.7743\n",
            "Epoch 11/50\n",
            "514/514 [==============================] - 0s 170us/step - loss: 0.4884 - acc: 0.7743\n",
            "Epoch 12/50\n",
            "514/514 [==============================] - 0s 178us/step - loss: 0.4784 - acc: 0.7782\n",
            "Epoch 13/50\n",
            "514/514 [==============================] - 0s 159us/step - loss: 0.4709 - acc: 0.7782\n",
            "Epoch 14/50\n",
            "514/514 [==============================] - 0s 141us/step - loss: 0.4644 - acc: 0.7782\n",
            "Epoch 15/50\n",
            "514/514 [==============================] - 0s 167us/step - loss: 0.4588 - acc: 0.7840\n",
            "Epoch 16/50\n",
            "514/514 [==============================] - 0s 151us/step - loss: 0.4539 - acc: 0.7899\n",
            "Epoch 17/50\n",
            "514/514 [==============================] - 0s 152us/step - loss: 0.4500 - acc: 0.7743\n",
            "Epoch 18/50\n",
            "514/514 [==============================] - 0s 140us/step - loss: 0.4463 - acc: 0.7840\n",
            "Epoch 19/50\n",
            "514/514 [==============================] - 0s 141us/step - loss: 0.4432 - acc: 0.7879\n",
            "Epoch 20/50\n",
            "514/514 [==============================] - 0s 141us/step - loss: 0.4398 - acc: 0.7879\n",
            "Epoch 21/50\n",
            "514/514 [==============================] - 0s 139us/step - loss: 0.4363 - acc: 0.7938\n",
            "Epoch 22/50\n",
            "514/514 [==============================] - 0s 158us/step - loss: 0.4340 - acc: 0.7957\n",
            "Epoch 23/50\n",
            "514/514 [==============================] - 0s 140us/step - loss: 0.4307 - acc: 0.7938\n",
            "Epoch 24/50\n",
            "514/514 [==============================] - 0s 153us/step - loss: 0.4284 - acc: 0.7938\n",
            "Epoch 25/50\n",
            "514/514 [==============================] - 0s 154us/step - loss: 0.4261 - acc: 0.8016\n",
            "Epoch 26/50\n",
            "514/514 [==============================] - 0s 167us/step - loss: 0.4231 - acc: 0.7977\n",
            "Epoch 27/50\n",
            "514/514 [==============================] - 0s 149us/step - loss: 0.4221 - acc: 0.8035\n",
            "Epoch 28/50\n",
            "514/514 [==============================] - 0s 158us/step - loss: 0.4190 - acc: 0.8152\n",
            "Epoch 29/50\n",
            "514/514 [==============================] - 0s 149us/step - loss: 0.4174 - acc: 0.8035\n",
            "Epoch 30/50\n",
            "514/514 [==============================] - 0s 160us/step - loss: 0.4159 - acc: 0.8132\n",
            "Epoch 31/50\n",
            "514/514 [==============================] - 0s 142us/step - loss: 0.4134 - acc: 0.8054\n",
            "Epoch 32/50\n",
            "514/514 [==============================] - 0s 153us/step - loss: 0.4115 - acc: 0.8016\n",
            "Epoch 33/50\n",
            "514/514 [==============================] - 0s 145us/step - loss: 0.4110 - acc: 0.8074\n",
            "Epoch 34/50\n",
            "514/514 [==============================] - 0s 141us/step - loss: 0.4087 - acc: 0.8152\n",
            "Epoch 35/50\n",
            "514/514 [==============================] - 0s 165us/step - loss: 0.4075 - acc: 0.8035\n",
            "Epoch 36/50\n",
            "514/514 [==============================] - 0s 138us/step - loss: 0.4051 - acc: 0.8074\n",
            "Epoch 37/50\n",
            "514/514 [==============================] - 0s 153us/step - loss: 0.4037 - acc: 0.8093\n",
            "Epoch 38/50\n",
            "514/514 [==============================] - 0s 143us/step - loss: 0.4025 - acc: 0.8093\n",
            "Epoch 39/50\n",
            "514/514 [==============================] - 0s 146us/step - loss: 0.4002 - acc: 0.8152\n",
            "Epoch 40/50\n",
            "514/514 [==============================] - 0s 152us/step - loss: 0.3987 - acc: 0.8113\n",
            "Epoch 41/50\n",
            "514/514 [==============================] - 0s 141us/step - loss: 0.3973 - acc: 0.8132\n",
            "Epoch 42/50\n",
            "514/514 [==============================] - 0s 156us/step - loss: 0.3956 - acc: 0.8230\n",
            "Epoch 43/50\n",
            "514/514 [==============================] - 0s 147us/step - loss: 0.3951 - acc: 0.8093\n",
            "Epoch 44/50\n",
            "514/514 [==============================] - 0s 142us/step - loss: 0.3935 - acc: 0.8093\n",
            "Epoch 45/50\n",
            "514/514 [==============================] - 0s 146us/step - loss: 0.3910 - acc: 0.8152\n",
            "Epoch 46/50\n",
            "514/514 [==============================] - 0s 157us/step - loss: 0.3894 - acc: 0.8113\n",
            "Epoch 47/50\n",
            "514/514 [==============================] - 0s 146us/step - loss: 0.3892 - acc: 0.8210\n",
            "Epoch 48/50\n",
            "514/514 [==============================] - 0s 147us/step - loss: 0.3873 - acc: 0.8191\n",
            "Epoch 49/50\n",
            "514/514 [==============================] - 0s 154us/step - loss: 0.3861 - acc: 0.8171\n",
            "Epoch 50/50\n",
            "514/514 [==============================] - 0s 140us/step - loss: 0.3844 - acc: 0.8210\n",
            "254/254 [==============================] - 0s 166us/step\n",
            "Accuracy: 73.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvgrOCXu9ic_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22ecc986-9fdd-41c3-ac50-7b84bf14057a"
      },
      "source": [
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 73.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFl-LNp09ooR",
        "colab_type": "text"
      },
      "source": [
        "Make Some Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPpM7AlS9rG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09010535-01ca-40ee-c383-c2f2d7bd5512"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# round predictions\n",
        "rounded = [round(x[0]) for x in y_pred]\n",
        "\n",
        "# Or use a function\n",
        "# make class predictions with the model\n",
        "y_pred = model.predict_classes(X_test)\n",
        "y_pred "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS42HYgg914J",
        "colab_type": "text"
      },
      "source": [
        "Create A Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPIueosS91EM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b9731def-12e3-4f9a-f5f1-4b97496b7a26"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score\n",
        "\n",
        "# Confusion matrix\n",
        "confusion_matrix(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "(tn, fp, fn, tp)\n",
        "\n",
        "pred_acc = (tn+tp)/(tn+tp+fp+fn)\n",
        "print(round(pred_acc,2))\n",
        "\n",
        "ps = precision_score(y_test, y_pred)\n",
        "ps\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.73\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}